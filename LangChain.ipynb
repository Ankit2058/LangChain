{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5180d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'summary_text': 'AI can help detect diseases earlier and personalize treatments . in healthcare, itâ€™s used'}\n",
      "AI can help detect diseases earlier and personalize treatments . in healthcare, itâ€™s used\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-small\")\n",
    "\n",
    "text = \"\"\"summarize: Artificial intelligence is transforming industries across the globe. From healthcare to finance, AI systems are being used to analyze massive datasets, identify patterns, and make predictions with incredible accuracy. In healthcare, AI can help detect diseases earlier and personalize treatments. In finance, itâ€™s used for fraud detection and algorithmic trading. As AI continues to advance, it raises questions about ethics, job displacement, and the need for new regulations.\"\"\"\n",
    "\n",
    "summary = summarizer(text, max_length=20, min_length=15, do_sample=True)\n",
    "print(summary[0])\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd8f777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ **Generated Summary:**\n",
      "this is the first time i am doing anything as text summary using the locally available model . ai ask you think and you being able to give it various inputs .\n",
      "\n",
      "ðŸ”¹ **Answer:**\n",
      "being able to give it various inputs .\n",
      "\n",
      "ðŸ”¹ **Answer:**\n",
      "to give it various inputs .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers.utils.logging import set_verbosity_error\n",
    "\n",
    "set_verbosity_error()\n",
    "\n",
    "summarization_pipeline = pipeline(\"summarization\", model=\"t5-small\", device=0)\n",
    "summarizer = HuggingFacePipeline(pipeline=summarization_pipeline)\n",
    "\n",
    "refinement_pipeline = pipeline(\"summarization\", model=\"t5-small\", device=0)\n",
    "refiner = HuggingFacePipeline(pipeline=refinement_pipeline)\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"t5-small\", device=0)\n",
    "\n",
    "summary_template = PromptTemplate.from_template(\"Summarize the following text in a {length} way:\\n\\n{text}\")\n",
    "\n",
    "summarization_chain = summary_template | summarizer | refiner\n",
    "\n",
    "text_to_summarize = input(\"\\nEnter text to summarize:\\n\")\n",
    "length = input(\"\\nEnter the length (short/medium/long): \")\n",
    "\n",
    "summary = summarization_chain.invoke({\"text\": text_to_summarize, \"length\": length})\n",
    "\n",
    "print(\"\\nðŸ”¹ **Generated Summary:**\")\n",
    "print(summary)\n",
    "\n",
    "while True:\n",
    "    question = input(\"\\nAsk a question about the summary (or type 'exit' to stop):\\n\")\n",
    "    if question.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    qa_result = qa_pipeline(question=question, context=summary)\n",
    "\n",
    "    print(\"\\nðŸ”¹ **Answer:**\")\n",
    "    print(qa_result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8198c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
